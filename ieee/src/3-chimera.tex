\section{ChimeraTL}
% \subsection{Overview}
ChimeraTL is a novel transfer learning method that combines the elements of ModelShift, DataReuseTL, and L2S in a way that maximizes their advantages and minimizes their disadvantages.
It consists of three procedures: (1) parameter selection and separation, (2) linear transformation learning, and (3) non-linear parameter learning.

\subsection{Parameter Selection and Separation}
\label{sec:parameter_selection}
The first step of ChimeraTL is to select parameters that have a significant impact on performance and separate them into linear parameters and non-linear parameters.

In the studies of DBMS performance models, parameter selection is a common practice because the number of parameters in DBMS is usually large, and not all of them have a significant impact on performance\cite{mysql197,Ottertune}.
Parameter selection can be done manually by experts, but it is time-consuming and requires a deep understanding of the DBMS.
Therefore, we use a feature selection method that automatically selects parameters that have a significant impact on performance.
As in L2S\cite{l2s}, we use stepwise regression\cite{stepwise} as the feature selection method.

While many studies have incorporated parameter selection into their approach, to the best of our knowledge, there is no existing method that separates parameters into linear and non-linear parameters.
Therefore, we propose a novel algorithm that uses Bhattacharyya distance\cite{bhattacharyya} to separate parameters based on the difference in their performance functions between two environments.

% TODO: make the algorithm more correct
\begin{algorithm}\small
  \caption{Parameter separation}
  \label{alg:separation}
  \begin{algorithmic}[1]
      \Require 
        \Statex $\boldsymbol{P}$: set of parameters
        \Statex $f_{1}$: performance function in environment 1
        \Statex $f_{2}$: performance function in environment 2
        \Statex $T$: threshold
      \Ensure 
        \Statex $\boldsymbol{P_{lr}}$: set of linear parameters
        \Statex $\boldsymbol{P_{nl}}$: set of non-linear parameters
      \Statex

      \State $\boldsymbol{P_{lr}} \gets \emptyset$
      \State $\boldsymbol{P_{nl}} \gets \emptyset$
      \For{$\boldsymbol{p_i} \in \boldsymbol{P}$}
          \State $p_{1}(\boldsymbol{p_i}) \gets \text{normalize}(f_{1}(\boldsymbol{p_i}))$\label{alg:separation:norm1}
          \State $p_{2}(\boldsymbol{p_i}) \gets \text{normalize}(f_{2}(\boldsymbol{p_i}))$\label{alg:separation:norm2}
          \State $d \gets \text{BhattacharyyaDistance}(p_{1}(\boldsymbol{p_i}), p_{2}(\boldsymbol{p_i}))$\label{alg:separation:distance}
          \If{$d < T$}\label{alg:separation:threshold}
              \State $\boldsymbol{P_{lr}} \gets \boldsymbol{P_{lr}} \cup \boldsymbol{p_i}$
          \Else
              \State $\boldsymbol{P_{nl}} \gets \boldsymbol{P_{nl}} \cup \boldsymbol{p_i}$
          \EndIf
      \EndFor
      \State \Return $\boldsymbol{P_{lr}}$, $\boldsymbol{P_{nl}}$
  \end{algorithmic}
\end{algorithm}

Bhattacharyya distance is a measure of the similarity between two probability distributions.
There are two advantages of using Bhattacharyya distance for parameter separation.
First, Bhattacharyya distance takes into account the shape of the probability distributions.
As opposed to only comparing the mean, variance, or largest absolute difference between two distributions\cite{kstest}, Bhattacharyya distance considers the entire distribution.
Even if two distributions have similar trends for some values, Bhattacharyya distance will be large if they have different trends for other values.
Second, Bhattacharyya distance is a symmetric measure, meaning that the distance between two distributions is the same regardless of which distribution is used as the reference.
Because of this property, setting a threshold on the distance is intuitive and easy to interpret.

The parameter separation algorithm is shown in Algorithm~\ref{alg:separation}.
The initial step of the algorithm is to convert each performance function of a parameter into a probability distribution.
This is done by normalizing the performance function so that the sum of the measured values becomes 1 (Line \ref{alg:separation:norm1}, \ref{alg:separation:norm2}).
Then, the Bhattacharyya distance between the two probability distributions is calculated (Line \ref{alg:separation:distance}).
If the distance is smaller than a threshold $T$, the parameter is considered to be linear, and otherwise it is considered to be non-linear (Line \ref{alg:separation:threshold}).
ChimeraTL uses the threshold to decide the trade-off between including more parameters in the linear group to reduce the number of samples required for model construction, and including more parameters in the non-linear group to reduce the risk of negative transfer.
The intuition behind this algorithm is that the parameters that have a performance function with a similar shape in different environments are likely to be linear, and vice versa (Fig.~\ref{fig:params}).


\subsection{Sampling in the Target Environment}
Once the parameters are separated into linear and non-linear parameters, ChimeraTL is ready to collect data from the target environment. 
There are two ways ChimeraTL collects data from the target environment.
For the first few samples, ChimeraTL focuses on collecting data of linear parameters to learn the linear transformation between the source and target environments.
With just a few samples, ChimeraTL can learn the linear transformation and reuse the source environment data of linear parameters for target model construction.
After collecting a set amount of samples for linear transformation learning, ChimeraTL prioritizes collecting data of non-linear parameters which are not available in the source environment.

One iteration of the sampling process is shown in Algorithm~\ref{alg:sampling}.
The sampling rate of linear parameters ($lr$) and the number of samples for priority switching ($N$) are the two parameters of ChimeraTL that control the sampling process.
In our implementation, we set $lr$ to 90\% initially, and switch to 10\% after collecting 5 samples for linear transformation learning (Line \ref{alg:sampling:n}, \ref{alg:sampling:lr}).

At the end of each iteration, ChimeraTL fits a performance prediction model using the collected data.
We use Gaussian Process (GP) regression\cite{gp} as the performance prediction model because it is known to be effective in modeling the performance of configurable software systems\cite{l2s,Ottertune,restune,Onlinetune,datareuse}.

\begin{algorithm}\small
  \caption{Sampling in the target environment}
  \label{alg:sampling}
  \begin{algorithmic}[1]
    \Require
      \Statex $\boldsymbol{P_{lr}}$: set of linear parameters
      \Statex $\boldsymbol{P_{nl}}$: set of non-linear parameters
      \Statex $N$: number of samples for priority switching
      \Statex $lr$: sampling rate of linear parameters
      \Statex $f_{src}$: performance function in the source environment
      \Statex $\text{model}$: performance prediction model
    \Ensure 
      \Statex $D_{tgt}$: target data
      \Statex $D_{lr}^{tgt}$: target data of linear parameters
      \Statex $D_{lr}^{src}$: source data of linear parameters
    \Statex

    \Function{RunNextIteration}{}
      \State $\text{sample\_linear} \gets \text{Random}() < lr$
      \If{$\text{sample\_linear}$}
        \State $\text{SampleLinear}()$
        \If{$\text{size}(D_{lr}^{tgt}) = N$}\label{alg:sampling:n}
          \State $lr \gets 1 - lr$\label{alg:sampling:lr}
        \EndIf
      \Else
        \State $\text{SampleNonLinear}()$
      \EndIf
      \State $\text{FitModel}(D_{train})$
    \EndFunction

    \State

    \Function{SampleLinear}{}\label{alg:sampling:regression}
      \State $\boldsymbol{p_i} \gets \text{RandomChoice}(\boldsymbol{P_{lr}})$
      \State $D_{lr}^{src} \gets D_{lr}^{src} \cup \{f_{src}(\boldsymbol{p_i}\}$
      \State $D_{lr}^{tgt} \gets D_{lr}^{tgt} \cup \{\text{sample}(f_{tgt}(\boldsymbol{p_i})\}$
      \State $\text{regression\_data} \gets \text{MergeOnConfig}(D_{lr}^{src}, D_{lr}^{tgt})$
      \State $\boldsymbol{\beta} \gets \text{LinearRegression}(\text{regression\_data})$
      \State $D_{tgt} \gets D_{tgt} \cup \{f_{tgt}(\boldsymbol{p_i})\}$
    \EndFunction

    \State

    \Function{SampleNonLinear}{}
      \State $\boldsymbol{p_i} \gets \text{RandomChoice}(\boldsymbol{P_{nl}})$
      \State $D_{tgt} \gets D_{tgt} \cup \{f_{tgt}(\boldsymbol{p_i})\}$
    \EndFunction

    \State

    \Function{FitModel}{}
      \State $\text{linearly\_related\_data} \gets \{f_{src}(\boldsymbol{p_i}) \,|\, \boldsymbol{p_i} \in \boldsymbol{P_{lr}}\}$
      \State $\text{data} \gets \text{Transform}(\text{linearly\_related\_data}, \boldsymbol{\beta})$\label{alg:sampling:transform}
      \State $\text{data} \gets \{d \in \text{data} \,|\, \text{Config}(d) \notin \text{Config}(D_{tgt})\}$
      \State $\text{data} \gets \text{data} \cup D_{tgt}$\label{alg:sampling:alldata}
      \State $\text{model.fit}(\text{data})$
    \EndFunction
    
  \end{algorithmic}
\end{algorithm}

\subsubsection{Linear Transformation Learning}
Learning the linear transformation between the source and target environments is an essential step that enables ChimeraTL to reuse the data of linear parameters from the source environment.
Reusing the linearly transformed source data dramatically reduces the number of samples from the target environment required to build a model.

Each time a new sample of linear parameters is collected from the target environment, ChimeraTL merges the sample with the source environment data of the same configuration and fits a linear regression model to the merged data (Line \ref{alg:sampling:regression}).
The linear regression model is used to transform the data of linear parameters in the source environment into an estimation of the data in the target environment (Line \ref{alg:sampling:transform}).
The transformed data is then combined with the samples from the target environment to build a performance prediction model (Line \ref{alg:sampling:alldata}).

Unlike ModelShift\cite{Valov}, ChimeraTL does not assume that all the parameters are linear.
Constructing a linear regression model using all the parameters would cause negative transfer because the non-linear parameters may not follow the pattern of the linear parameters.
Instead, ChimeraTL only samples the data of linear parameters selected in Section~\ref{sec:parameter_selection} to learn the linear regression.
Similarly, the linear regression model is only used to transform the source data of linear parameters, and the source data of non-linear parameters are not used in the target model construction.

\subsubsection{Non-linear Parameter Learning}
Initially, ChimeraTL samples the data of linear parameters more frequently than the other parameters.
However, the benefit of sampling those data diminishes after learning the linear transformation because the linearly transformed source data can substitute the target environment data of linear parameters for model construction.
Once there are enough data of the linear parameters, ChimeraTL prioritizes sampling the data of non-linear parameters from the target environment.
This strategy is based on the fact that the non-linear parameters have different effects on performance depending on the hardware limitations, and the trends of these parameters are not observable in the source environment.
Therefore, ChimeraTL collects the data of non-linear parameters more often than the other parameters to learn the target-environment specific trends of these parameters.

% TODO: write about GP